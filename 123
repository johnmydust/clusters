---
- name: OpenShift Worker Node Network Connectivity Check
  hosts: localhost
  gather_facts: false
  
  vars:
    namespace: services
    registry_image: busybox:latest
    test_deployment_name: registry-check

  tasks:
    - name: Define cleanup tasks
      set_fact:
        cleanup_tasks:
          - name: Remove exposed registry route
            command: >
              oc patch configs.imageregistry.operator.openshift.io/cluster 
              --type merge 
              -p '{"spec":{"defaultRoute":false}}'
            ignore_errors: true

          - name: Delete deployment
            command: oc delete deployment {{ test_deployment_name }} -n {{ namespace }}
            ignore_errors: true

          - name: Delete imagestream
            command: oc delete imagestream busybox -n {{ namespace }}
            ignore_errors: true

          - name: Clean up node images
            shell: |
              WORKER_NODE=$(oc get nodes -l node-role.kubernetes.io/worker -o name | head -1 | cut -d'/' -f2)
              oc debug node/$WORKER_NODE -- bash -ec "
                chroot /host bash -ec \"
                  podman images | grep busybox && podman rmi -f \$(podman images | grep busybox | awk '{print \$3}') || true
                  podman system prune -f
                \"
              "
            ignore_errors: true

    - block:
        # Initial Checks and Setup
        - name: Check if logged into OpenShift
          command: oc whoami
          register: login_check
          ignore_errors: true

        - name: Fail if not logged into OpenShift
          fail:
            msg: "Not logged into OpenShift. Please run 'oc login' first."
          when: login_check.rc != 0

        - name: Get current project
          command: oc project -q
          register: current_project

        - name: Switch to services namespace
          command: oc project {{ namespace }}

        # Initial Cleanup
        - name: Initial cleanup of previous resources
          include_tasks: "{{ cleanup_tasks }}"

        # Get Worker Nodes Information
        - name: Get worker nodes
          kubernetes.core.k8s_info:
            kind: Node
            label_selectors:
              - node-role.kubernetes.io/worker
          register: worker_nodes

        - name: Set worker node facts
          set_fact:
            worker_node_list: "{{ worker_nodes.resources | map(attribute='metadata.name') | list }}"
            worker_count: "{{ worker_nodes.resources | length }}"

        - name: Fail if no worker nodes found
          fail:
            msg: "No worker nodes found in the cluster"
          when: worker_count == 0

        # Registry Setup
        - name: Get cluster domain
          kubernetes.core.k8s_info:
            api_version: config.openshift.io/v1
            kind: Ingress
            name: cluster
          register: cluster_info

        - name: Set cluster domain
          set_fact:
            cluster_domain: "{{ cluster_info.resources[0].spec.domain }}"

        - name: Expose OpenShift internal registry
          command: >
            oc patch configs.imageregistry.operator.openshift.io/cluster 
            --type merge 
            -p '{"spec":{"defaultRoute":true}}'

        - name: Wait for registry route hostname
          shell: |
            oc get route default-route -n openshift-image-registry -o jsonpath='{.spec.host}'
          register: registry_host
          until: registry_host.stdout != ""
          retries: 30
          delay: 10

        # Get Authentication Token
        - name: Get OpenShift authentication token
          command: oc whoami -t
          register: oc_token

        # Container Operations on Worker Node
        - name: Debug worker node and perform registry operations
          shell: |
            WORKER_NODE=$(oc get nodes -l node-role.kubernetes.io/worker -o name | head -1 | cut -d'/' -f2)
            
            oc debug node/$WORKER_NODE -- bash -ec "
              echo 'Starting registry operations on node: $WORKER_NODE'
              
              chroot /host bash -ec \"
                # Clean up existing images first
                echo 'Cleaning up existing images...'
                podman images | grep busybox && podman rmi -f \$(podman images | grep busybox | awk '{print \$3}') || true
                
                # Clean up any dangling images
                echo 'Cleaning up dangling images...'
                podman system prune -f
                
                # Explicitly pull from docker.io
                echo 'Pulling fresh image from docker.io...'
                podman pull docker.io/library/busybox:latest && \
                
                # Verify the image source
                echo 'Image details:'
                podman inspect docker.io/library/busybox:latest | grep 'RepoTags\|RepoDigests' && \
                
                # Login and push to internal registry
                echo 'Logging into internal registry...'
                podman login -u {{ login_check.stdout }} \
                  -p {{ oc_token.stdout }} \
                  --tls-verify=false \
                  default-route-openshift-image-registry.apps.{{ cluster_domain }} && \
                
                echo 'Tagging image...'
                podman tag docker.io/library/busybox:latest \
                  default-route-openshift-image-registry.apps.{{ cluster_domain }}/{{ namespace }}/busybox:latest && \
                
                echo 'Pushing to internal registry...'
                podman push --tls-verify=false \
                  default-route-openshift-image-registry.apps.{{ cluster_domain }}/{{ namespace }}/busybox:latest
              \"
            "
          register: debug_result

        - name: Display debug operation results
          debug:
            msg: "{{ debug_result.stdout_lines }}"

        # Create Test Deployment
        - name: Create test deployment
          command: |
            cat << EOF | oc apply -f -
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: {{ test_deployment_name }}
              namespace: {{ namespace }}
            spec:
              replicas: {{ worker_count }}
              selector:
                matchLabels:
                  app: {{ test_deployment_name }}
              template:
                metadata:
                  labels:
                    app: {{ test_deployment_name }}
                spec:
                  affinity:
                    nodeAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                        nodeSelectorTerms:
                        - matchExpressions:
                          - key: kubernetes.io/hostname
                            operator: In
                            values: {{ worker_node_list | to_yaml }}
                  containers:
                  - name: test-container
                    image: image-registry.openshift-image-registry.svc:5000/{{ namespace }}/{{ registry_image }}
                    command: ["sleep", "3600"]
            EOF

        # Verify Deployment
        - name: Wait for deployment to be ready
          command: |
            oc rollout status deployment/{{ test_deployment_name }} -n {{ namespace }}
          register: rollout_status

        - name: Get pods status
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            namespace: "{{ namespace }}"
            label_selectors:
              - app={{ test_deployment_name }}
          register: test_pods

        # Check for failing pods
        - name: Get failing pods details
          when: test_pods.resources | length != worker_count
          block:
            - name: Get events for failing pods
              shell: |
                oc get events -n {{ namespace }} --field-selector involvedObject.kind=Pod,involvedObject.namespace={{ namespace }}
              register: pod_events

            - name: Display failing pods information
              debug:
                msg: "{{ pod_events.stdout_lines }}"

        # Show final distribution
        - name: Show pod distribution
          shell: |
            oc get pods -l app={{ test_deployment_name }} -o wide
          register: pod_distribution

        - name: Display pod distribution
          debug:
            msg: "{{ pod_distribution.stdout_lines }}"

      rescue:
        - name: Display failure message
          debug:
            msg: "Network connectivity test failed, starting cleanup..."

        - name: Run cleanup tasks on failure
          include_tasks: "{{ cleanup_tasks }}"

      always:
        - name: Return to original project
          command: oc project {{ current_project.stdout }}

        - name: Final cleanup
          include_tasks: "{{ cleanup_tasks }}"

        - name: Display completion message
          debug:
            msg: "Network connectivity test completed. All resources have been cleaned up."
